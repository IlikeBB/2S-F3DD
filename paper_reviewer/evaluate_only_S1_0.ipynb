{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "# %env SM_FRAMEWORK=tf.keras\n",
    "import zipfile, os, numpy as np, pickle, yaml, gc, tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import tensorflow_addons as tfa\n",
    "sys.path.append(\"..\")\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "from sklearn.metrics import jaccard_score\n",
    "from segmentation_models import Unet\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "class_type = 0 # 0=NL, 1=AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path test\n",
    "top_layer_path_train = '../my_data/datasets/all_seg_data_NL_zm_2/'\n",
    "top_layer_path = '../my_data/datasets/test_data_NL/'\n",
    "# S1 [img, msk]\n",
    "S1_img_stack = ['T3_image_arr_384_valid.npy', 'T3_masks_arr_384_valid.npy', 'T3_image_arr_384_train.npy', 'T3_masks_arr_384_train.npy']\n",
    "# save path\n",
    "# save_path = f'results_log/S1/all_S1-test_results_{datatype}'\n",
    "\n",
    "\n",
    "# S1 model weight path\n",
    "S1_weights=['../checkpoints/S1-segment/2DResNet50-384-epochs_100-lr_0.001-batch_8-2022.04.07-original_3T_NL-data_FTL-20--sample.hdf5',\n",
    "                            '../checkpoints/S1-segment/2DResNet50-384-epochs_100-lr_0.001-batch_8-2022.04.07-original_3T_NL-data_FTL-50--sample.hdf5',\n",
    "                            '../checkpoints/S1-segment/2DResNet50-384-epochs_100-lr_0.001-batch_8-2022.04.07-original_3T_NL-data_FTL-100--sample.hdf5',\n",
    "                            '../my_data/my_weights/S1_ResNet.hdf5',\n",
    "                            '../my_data/my_weights/S1_DenseNet.hdf5',\n",
    "                            '../my_data/my_weights/S1_VGGNet.hdf5']\n",
    "# S1_weights=['./checkpoints/S1-segment/best-valid-auc_2DDenseUnet-12.16-original_3T_NL-data_dice-loss.hdf5', './checkpoints/S1-segment/best-valid-auc_2DResNet50-12.16-original_3T_NL-data_dice-loss.hdf5', config[\"S1_vgg\"]]\n",
    "S1_backbone = ['resnet50', 'resnet50', 'resnet50', 'resnet50','densenet121','vgg16']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S1_dataloader(valid_data='Mix', tune_type='test', data_len=None):\n",
    "    if tune_type=='test':\n",
    "        img_layer_path = top_layer_path\n",
    "        if valid_data == '3.0T':\n",
    "            # loading valida data 3.0T + 1.5T: image / masks\n",
    "            X_valid = np.load(img_layer_path +'/'+ S1_img_stack[0])[0:10]\n",
    "            y_valid = np.load(img_layer_path +'/'+ S1_img_stack[1])[0:10]\n",
    "    elif tune_type=='train':\n",
    "        img_layer_path = top_layer_path_train\n",
    "        if data_len == 999:\n",
    "            X_valid = np.load(img_layer_path +'/'+ S1_img_stack[2])\n",
    "            y_valid = np.load(img_layer_path +'/'+ S1_img_stack[3])\n",
    "        else:\n",
    "            X_valid = np.load(img_layer_path +'/'+ S1_img_stack[2])[0: data_len]\n",
    "            y_valid = np.load(img_layer_path +'/'+ S1_img_stack[3])[0: data_len]\n",
    "        \n",
    "    X_valid = np.reshape(X_valid, (X_valid.shape[0]*32,384,384,1))\n",
    "    y_valid = np.reshape(y_valid, (y_valid.shape[0]*32,384,384,1))\n",
    "    return X_valid.astype(np.float32), y_valid.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S1_model_loader(weight_path, backbone, mode, data_len=None):\n",
    "    S1_X_valid, S1_y_valid= S1_dataloader(valid_data='3.0T', tune_type=mode, data_len=data_len)\n",
    "    print(f'S1 data shape: img {S1_X_valid.shape} msk {S1_y_valid.shape}')\n",
    "    model = Unet(backbone, encoder_weights=None, input_shape=(None, None, 1))\n",
    "    model.load_weights(weight_path)\n",
    "    Results = model.predict(S1_X_valid, batch_size=1, verbose=1)\n",
    "    return np.array(Results), np.array(S1_X_valid), np.array(S1_y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "class metric_:\n",
    "    def __init__(self,y_true, y_pred):\n",
    "        self.y_true_f = K.flatten(y_true)\n",
    "        self.y_pred_f = K.flatten(y_pred)\n",
    "        self.current = confusion_matrix(K.cast(self.y_true_f, dtype='int8'), K.cast(self.y_pred_f, dtype='int8'), labels=[0, 1])\n",
    "        # [[47159744      337]\n",
    "        # [   16462     9377]]\n",
    "    def dice_coef(self):\n",
    "        # intersection = K.sum(self.y_true_f* self.y_pred_f )\n",
    "        intersection = np.diag(self.current)\n",
    "        ground_truth_set = self.current.sum(axis=1)\n",
    "        predicted_set = self.current.sum(axis=0)\n",
    "        # dice = (2. * intersection) / (K.sum(self.y_true_f) + K.sum(self.y_pred_f ))\n",
    "        dice = (2. * intersection) / (ground_truth_set + predicted_set)\n",
    "        return np.mean(dice)\n",
    "        \n",
    "    def iou(self):\n",
    "        # ytrue, ypred is a flatten vector\n",
    "        # compute mean iou\n",
    "        intersection = np.diag(self.current)\n",
    "        ground_truth_set = self.current.sum(axis=1)\n",
    "        predicted_set = self.current.sum(axis=0)\n",
    "        union = ground_truth_set + predicted_set - intersection\n",
    "        IoU = intersection / union.astype(np.float32)\n",
    "        return np.mean(IoU)\n",
    "    def acc(self):\n",
    "        tn, fp, fn, tp = self.current .ravel()\n",
    "        return ((tp+tn)/(tp+fp+fn+tn))\n",
    "        # \"Accuracy: \"+str(round((tp+tn)/(tp+fp+fn+tn), 3))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model = test\n",
      "Train Sample = 20 - resnet50\n",
      "S1 data shape: img (320, 384, 384, 1) msk (320, 384, 384, 1)\n",
      "320/320 [==============================] - 90s 281ms/step\n",
      "Dice:  0.7636580439733235\n",
      "IoU:   0.6789364014044497\n",
      "Acc:   0.9996439827813043\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dfadfa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0b1caa704930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IoU:  \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Acc:  \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfadfa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# S1_pred_stack.append([S1_pred, S1_y_valid])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# print(\"Dice: \", dice_coef(S1_y_valid,S1_pred).numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dfadfa' is not defined"
     ]
    }
   ],
   "source": [
    "# ----S1 model test 1 - 3----\n",
    "mode_list=['test']\n",
    "train_data_len = [20,50,100,999,999,999]\n",
    "for idx,d in enumerate(mode_list):\n",
    "    print(f'Start model = {d}')\n",
    "    for i in range(6):\n",
    "        if train_data_len[i]==999:\n",
    "            print(f'Train Sample = 140 - {S1_backbone[i]}')\n",
    "        else:\n",
    "            print(f'Train Sample = {train_data_len[i]} - {S1_backbone[i]}')\n",
    "        if d == 'train':\n",
    "            S1_pred, S1_X_valid, S1_y_valid = S1_model_loader(S1_weights[i], S1_backbone[i], d, data_len=train_data_len[i])\n",
    "        else:\n",
    "            S1_pred, S1_X_valid, S1_y_valid = S1_model_loader(S1_weights[i], S1_backbone[i], d)\n",
    "        metric_class = metric_(S1_y_valid,S1_pred)\n",
    "        print(\"Dice: \", metric_class.dice_coef())\n",
    "        print(\"IoU:  \", metric_class.iou())\n",
    "        print(\"Acc:  \", metric_class.acc())\n",
    "        print(dfadfa)\n",
    "        # S1_pred_stack.append([S1_pred, S1_y_valid])\n",
    "        # print(\"Dice: \", dice_coef(S1_y_valid,S1_pred).numpy())\n",
    "        # print(\"IoU:  \", iou(S1_y_valid,S1_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4665f7484a0bffeb453a5c4a3f9172c008eba4e225e0a746b21d144b5d5fbcdb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('SGD': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "5d33ac8ce81c8da01985ba1576671d92ac976b7a4615b42eb65ecef4f329b894"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
